{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer = nn.Conv2d(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    kernel_size=3,\n",
    "    stride=1,\n",
    "    padding=1\n",
    ")\n",
    "\n",
    "conv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 5, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer(torch.rand(1, 1, 5, 5)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling_layer = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "pooling_layer(torch.rand(1, 1, 5, 5)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "[[ 60. 113.  56. 139.  85.]\n",
      " [ 73. 121.  54.  84. 128.]\n",
      " [131.  99.  70. 129. 127.]\n",
      " [ 80.  57. 115.  69. 134.]\n",
      " [104. 126. 123.  95. 130.]]\n",
      "\n",
      "Kernel:\n",
      "[[ 0. -1.  0.]\n",
      " [-1.  5. -1.]\n",
      " [ 0. -1.  0.]]\n",
      "\n",
      "Output:\n",
      "[[ 114.  328.  -26.  470.  158.]\n",
      " [  53.  266.  -61.  -30.  344.]\n",
      " [ 403.  116.  -47.  295.  244.]\n",
      " [ 108. -135.  256. -128.  344.]\n",
      " [ 314.  346.  279.  153.  421.]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Criando uma camada Conv2d\n",
    "conv = nn.Conv2d(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    kernel_size=3,\n",
    "    bias=False,\n",
    "    padding=1\n",
    ")\n",
    "\n",
    "# Definindo um kernel personalizado (3x3)\n",
    "custom_kernel = torch.tensor(\n",
    "    [[ 0.0, -1.0,  0.0],\n",
    "     [-1.0,  5.0, -1.0],\n",
    "     [ 0.0, -1.0,  0.0]],\n",
    "     dtype=torch.float32\n",
    ")\n",
    "\n",
    "# Atribuindo o kernel à camada Conv2d\n",
    "# O peso precisa ter o formato (out_channels, in_channels, kernel_size, kernel_size)\n",
    "conv.weight.data = custom_kernel.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# Definindo a entrada com os valores da imagem (5x5)\n",
    "input_tensor = torch.tensor(\n",
    "    [[\n",
    "        [60, 113, 56, 139, 85],\n",
    "        [73, 121, 54, 84, 128],\n",
    "        [131, 99, 70, 129, 127],\n",
    "        [80, 57, 115, 69, 134],\n",
    "        [104, 126, 123, 95, 130],\n",
    "    ]], dtype=torch.float32\n",
    ").unsqueeze(0)  # Adiciona batch dimension\n",
    "\n",
    "# Aplicando a convolução\n",
    "output = conv(input_tensor)\n",
    "\n",
    "# Resultado\n",
    "print(\"Input:\")\n",
    "print(input_tensor.squeeze().numpy())\n",
    "\n",
    "print(\"\\nKernel:\")\n",
    "print(custom_kernel.numpy())\n",
    "\n",
    "print(\"\\nOutput:\")\n",
    "print(output.squeeze().detach().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de entrada:\n",
      "[[7. 3. 5. 2.]\n",
      " [8. 7. 1. 6.]\n",
      " [4. 9. 3. 9.]\n",
      " [0. 8. 4. 5.]]\n",
      "\n",
      "Matriz após MaxPooling:\n",
      "[[8. 6.]\n",
      " [9. 9.]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Matriz de entrada (4x4)\n",
    "input_tensor = torch.tensor(\n",
    "    [[7, 3, 5, 2],\n",
    "     [8, 7, 1, 6],\n",
    "     [4, 9, 3, 9],\n",
    "     [0, 8, 4, 5]],\n",
    "    dtype=torch.float32\n",
    ").unsqueeze(0).unsqueeze(0)  # Adiciona dimensões de batch e canais (1x1x4x4)\n",
    "\n",
    "# Definir o MaxPooling com kernel 2x2, stride 2 e sem padding\n",
    "maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "# Aplicar o MaxPooling\n",
    "output = maxpool(input_tensor)\n",
    "\n",
    "print(\"Matriz de entrada:\")\n",
    "print(input_tensor.squeeze().numpy())\n",
    "\n",
    "print(\"\\nMatriz após MaxPooling:\")\n",
    "print(output.squeeze().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
